{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties and Log Barriers\n",
    "\n",
    "Based on Homework at https://www.user.tu-berlin.de/mtoussai/teaching/13-Optimization/\n",
    "From M. Toussaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.PlotlyBackend()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "\n",
    "plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Equality Constraint Penalties and augmented Lagrangian\n",
    "\n",
    "(We don't need to know what the Langangian is (yet) to solving this exercise.) In the lecture we discussed the squared penalty method for inequality constraints. There is a straight-forward version for equality constraints: Instead of\n",
    "$$\\min _{x} f(x) \\quad \\text { s.t. } \\quad h(x)=0 $$\n",
    "we address\n",
    "$$ \\min _{x} f(x)+\\mu \\sum_{i=1}^{m} h_{i}(x)^{2} $$\n",
    "such that the squared penalty pulls the solution onto the constraint $h(x)=0 .$ Assume that if we minimize (2) we end up at a solution $x_{1}$ for which each $h_{i}\\left(x_{1}\\right)$ is reasonable small, but not exactly zero. We also mentioned the idea that we could add an additional term which counteracts the violation of the constraint. This can be realized by minimizing\n",
    "$$ \\min _{x} f(x)+\\mu \\sum_{i=1}^{m} h_{i}(x)^{2}+\\sum_{i=1}^{m} \\lambda_{i} h_{i}(x) $$\n",
    "for a \"good choice\" of each $\\lambda_{i}$. It turns we can infer this \"good choice\" from the solution $x_{1}$ of (2) \n",
    "\n",
    "#### Task:\n",
    "Prove that setting $\\lambda_{i}=2 \\mu h_{i}\\left(x_{1}\\right)$ will, if we assume that the gradients $\\nabla f(x)$ and $\\nabla h(x)$ are (locally) constant, ensure that the minimum of (3) fulfils exactly the constraints $h(x)=0$ \n",
    "\n",
    "Tip: Think intuitively. Think about how the gradient that arises from the penalty in (2) is now generated via the $\\lambda_{i}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "\n",
    "First, we think back to how we arrived at $\\lambda_i = 2 \\mu h_i(x_1)$. We first take the gradient of (2), which is the optimality condition:\n",
    "$$ \\nabla_{x} f(x)+\\mu \\nabla_{x} \\sum_{i=1}^{m} h_{i}(x)^{2} = 0 $$\n",
    "$$ \\nabla_{x} f(x)+\\mu \\sum_{i=1}^{m} 2 h_{i}(x) \\nabla_{x} h_i(x) = 0 $$\n",
    "\n",
    "We next take the gradient of (3), which is the optimality condition:\n",
    "\n",
    "$$ \\nabla_{x} f(x)+\\mu \\nabla_{x} \\sum_{i=1}^{m} h_{i}(x)^{2}+ \\nabla_{x} \\sum_{i=1}^{m} \\lambda_{i} h_{i}(x) = 0$$\n",
    "$$ \\nabla_{x} f(x)+\\mu \\sum_{i=1}^{m} 2 h_{i}(x) \\nabla_{x} h_i(x)+ \\sum_{i=1}^{m} \\lambda_{i} \\nabla_{x} h_{i}(x) = 0$$\n",
    "$$ \\nabla_{x} f(x)+\\sum_{i=1}^{m} (2 \\mu  h_{i}(x) + \\lambda_{i}) \\nabla_{x} h_i(x) = 0$$\n",
    "\n",
    "For optimization of (2), we get $x_1$ when $\\lambda_i = 0$. That is,\n",
    "$$\\lambda_{i}^{new} \\leftarrow 2 \\mu  h_{i}(x) + \\lambda_{i}^{old} = 2 \\mu h_i(x_1)$$\n",
    "\n",
    "The key assumptions are that $\\nabla_x f(x)$ and $\\nabla_x h(x)$ are (locally) constant. Hence, call the argmin of (3) = $x_2$. Then $\\nabla_x f(x_1) = \\nabla_x f(x_2)$ and $\\nabla_x h(x_1) = \\nabla_x h(x_2)$\n",
    "\n",
    "Therefore, we have \n",
    "$$ \\nabla_{x} f(x_1)+\\mu \\sum_{i=1}^{m} 2 h_{i}(x_1) \\nabla_{x} h_i(x_1) = 0 = \\nabla_{x} f(x_2)+\\mu \\sum_{i=1}^{m} 2 h_{i}(x_1) \\nabla_{x} h_i(x_2) $$\n",
    "\n",
    "Looking at the optimality condition with $x_2$, we have \n",
    "$$ \\nabla_{x} f(x_2)+\\mu \\sum_{i=1}^{m} 2 h_{i}(x_2) \\nabla_{x} h_i(x_2)+ \\sum_{i=1}^{m} \\lambda_{i} \\nabla_{x} h_{i}(x_2) = 0$$\n",
    "And with the current $\\lambda_i = 2 \\mu h_i(x_1)$, we have\n",
    "$$ \\underbrace{\\nabla_{x} f(x_2)}+\\mu \\sum_{i=1}^{m} 2 h_{i}(x_2) \\nabla_{x} h_i(x_2)+ \\underbrace{\\sum_{i=1}^{m} 2 \\mu h_i(x_1) \\nabla_{x} h_{i}(x_2)} = 0$$\n",
    "\n",
    "We now identify the conditions for optimality of (2) using the key assumptions that $\\nabla_x f(x)$ and $\\nabla_x h(x)$ are (locally) constant. So,\n",
    "$$\\mu \\sum_{i=1}^{m} 2 h_{i}(x_2) \\nabla_{x} h_i(x_2) = 0$$\n",
    "\n",
    "This new optimality condition is equivalent to \n",
    "$$ \\min _{x} \\mu \\sum_{i=1}^{m} h_{i}(x)^{2}$$\n",
    "\n",
    "Which occurs when $h(x) = 0$ as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Squared Penalties \\& Log Barriers\n",
    "\n",
    "In the last exercise we defined the \"hole function\" $f_{\\text {hole }}^{c}(x),$ where we now assume a conditioning $c=4$ Consider the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
